# 背景介绍

![image-20210805220455222](.\图片\项目背景.png)****

![image-20210805220741643](.\图片\仓储预测.png)

![image-20210805220825257](.\图片\仓促预测.png)

![image-20210805220903194](.\图片\仓储预测-1.png)

# 项目架构

![image-20210805221631139](.\图片\项目架构.png)



# Cloudera Manager架构

![image-20210805224619607](.\图片\CDH-架构.png)

# CDH安装

1、配置java环境变量

2、配置ssh

3、配置ntp

4、安装MySQL

5、初始化用户

```mysql
set global validate_password_policy=0;
set global validate_password_mixed_case_count=0;
set global validate_password_number_count=3;
set global validate_password_special_char_count=0;
set global validate_password_length=3;

# create user scm IDENTIFIED by 'scm';
grant all PRIVILEGES on scm.* to '%'@'%' identified by 'scm' with grant option;
grant all PRIVILEGES on scm.* to '%'@'localhost' identified by 'scm' with grant option;
flush privileges;
```

6、关闭防火墙、selinux

7、设置vm文件等

8、参考目录：https://blog.csdn.net/silentwolfyh/article/details/54893826



****

# 数据采集

![image-20210809214241830](.\图片\图片开发算法.png)

# 动态规划算

## 递归算法

递归：函数（方法）直接或间接调用自身，是一种常用的编程技巧。

严格来说，递归不算一种编程思想，更多地是一种编程技巧。



## 时间复杂度

时间复杂度，指令执行次数，指令：代码翻译为底层的汇编语言的指令，，，次数：运行次数，代码的执行次数

判断语句省略不计：

一个分好就是一句代码。

![image-20210811214408465](.\图片\时间复杂度.png)

![image-20210811215106972](.\图片\时间复杂度-1.png)

![image-20210811215543280](.\图片\时间复杂度-2.png)

![image-20210811215622104](.\图片\时间复杂度-3.png)



O(1)<O(logn)<O(n)<O(n*logn)<Olog(n^2)<O(n^3)<O(2^n)



## 空间复杂度

空间复杂度：讨论**方法内部**的局部变量占用的内存空间。

空间复杂度讨论的是算法执行时占用的内存空间（栈内存），现在硬件资源都比较充足，所以我们往往更关注时间复杂度。

大O表示法不是精确计算复杂度，而是一种估算。



## 递归算法



## 贪心算法

局部最优原则。

## 分治策略

分而治之。

1、将问题分解成若干个规模娇小的问题（子问题和原问题的结构一样，只是规模不一样）。

2、子问题又不断的分解成规模更小的问题，直到不能再分解（直到可以轻易计算出子问题的解）

3、利用子问题的解推导出原问题的解

**所以，分支非常适合使用递归实现**

注意：分治的适用场景必须要求子问题之间是相互独立的，如果子问题之间不独立则需要使用动态规划实现。

![image-20210814094015418](.\图片\分治算法-图解.png)

### 快排

![image-20210814095447016](.\图片\分治算法-快排.png)

## 递推式和时间复杂度



![image-20210814103504614](.\图片\递推式和时间复杂度.png)



## 动态规划

动态规划是求解最优化问题的一种常用策略。

动态规划使用步骤：

​	1、递归，自顶向下，出现了重叠子问题

​	2、记忆化，自顶向下，备忘录

​	3、递推，自底向上，循环

![image-20210814201058893](.\图片\动态规划-1.png)

![image-20210814201328671](.\图片\递归算法-使用步骤.png)





### 连续子序列

 ### 最长公共子序列

leetcode 1143

![image-20210815113140438](.\图片\动态规划-LCS-递推方式.png)

### 背包问题



# 车货匹配

​	动态规划。

## HDFS 

![image-20210816210633069](.\图片\设置返回外网ip.png)



# 指标体系

![image-20210816213046229](.\图片\指标体系.png)

![image-20210816213235810](.\图片\指标体系2.png)

# 实时处理

![image-20210816222649413](.\图片\实时处理.png)





## 安装Nginx

 ``` shell
 yum install wget git -y
 yum install gcc-c++ -y
 
 # 安装到/usr/local/src目录下
 cd /usr/local/src
 git clone https://github.com/edenhill/librdkafka
 
 cd /usr/local/src/librdkafka
 yum install -y gcc gcc-c++ pcre-devel zlib-devel
 ./configure
 make && make instal
 
 # 安装nginx，整合kafka
 cd /usr/local/src
 git clone https://github.com/brg-liuwei/ngx_kafka_module
 
 # 下载nginx
 cd /usr/local/src
 wget http://nginx.org/download/nginx-1.17.8.tar.gz
 tar -zxvf nginx-1.17.8.tar.gz
 cd nginx-1.17.8
 yum install gcc zlib zlib-devel openssl openssl-devel pcre pcre-devel -y
 
 # 进入到nginx的源码目录下(编译nginx，包含与kafka整合的插件)
 cd /usr/local/src/nginx-1.17.8
 ./configure --add-module=/usr/local/src/ngx_kafka_module/
 make && make install
 /usr/local/nginx/conf
 
 # 修改配置文件
 # /usr/local/nginx/conf下的nginx.conf文件，不要与之前下载的nginx安装包目录混淆！！
 
 #user nobody;
 worker_processes 1;
 #error_log logs/error.log;
 #error_log logs/error.log notice;
 #error_log logs/error.log info;
 #pid    logs/nginx.pid;
 events {
  worker_connections 1024;
 }
 http {
  include    mime.types;
  default_type application/octet-stream;
  #log_format main '$remote_addr - $remote_user [$time_local] "$request" '
  #         '$status $body_bytes_sent "$http_referer" '
  #         '"$http_user_agent" "$http_x_forwarded_for"';
  #access_log logs/access.log main;
  sendfile    on;
  #tcp_nopush   on;
  #keepalive_timeout 0;
  keepalive_timeout 65;
  kafka;
  kafka_broker_list hadoop2:9092,hadoop3:9092,hadoop4:9092;
  #gzip on;
  server {
    listen    80;
    server_name localhost;
 #charset koi8-r;
    #access_log logs/host.access.log main;
    location / {
      root  html;
      index index.html index.htm;
    }
    location = /log/lg_bus_info {
      kafka_topic lg_bus_info;
    }
    #error_page 404       /404.html;
    # redirect server error pages to the static page /50x.html
    #
    error_page  500 502 503 504 /50x.html;
    location = /50x.html {
      root  html;
    }
    # proxy the PHP scripts to Apache listening on 127.0.0.1:80
    #
    #location ~ \.php$ {
    #  proxy_pass  http://127.0.0.1;
    #}
    # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000
    #
    #location ~ \.php$ {
    #  root      html;
    #  fastcgi_pass  127.0.0.1:9000;
    #  fastcgi_index index.php;
    #  fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name;
    #  include    fastcgi_params;
    #}
    # deny access to .htaccess files, if Apache's document root
    # concurs with nginx's one
    #
    #location ~ /\.ht {
    #  deny all;
    #}
  }
  # another virtual host using mix of IP-, name-, and port-based configuration
  #
  #server {
  #  listen    8000;
  #  listen    somename:8080;
  #  server_name somename alias another.alias;
  #  location / {
  #    root  html;
  #    index index.html index.htm;
  #  }
  #}
 ```



## structured streaming

spark streaming这种构建在微批处理上的流计算引擎，**比较突出的问题就是处理延时较高（无法优化到秒以下的数量级）**，**以及无法支持基于event_time的时间窗口做聚合逻辑**。

**会话窗口**



### DataFlow模型。

在日常商业运营中，**无边界、乱序、大规模数据集**越来越普遍（例如，网站日志，手机应用统计，传感器网络）。同时，对这些数据的消费需求也越来越复杂，比如说按事件发生时间序列处理数据，按数据本身的特征进行窗口计算等等。同时人们也越来越苛求立刻得到数据分析结果。作为数据工作者，**不能把无边界数据集（数据流）切分成有边界的数据，等待一个批次完整后处理**。相反地，应该假设永远无法知道数据流是否终结，何时数据会变完整。唯一确信的是，新的数据会源源不断而来，老的数据可能会被撤销或更新。

**1、核心思想**

对无边界，无序的数据源，允许按数据本身的特征进行窗口计算，得到基于事件发生时间的有序结果，并能在准确性、延迟程度和处理成本之间调整。

**2、四个维度**



**3、相关概念**

### 介绍

- Structured Streaming是一个基于Spark SQL引擎的可扩展、容错的流处理引擎。统一了流、批的编程模型，你可以使用静态数据批处理一样的方式来编写流式计算操作。并且支持基于event_time的时间窗口的处理逻辑。
- Structured Streaming会以一种增量的方式来执行这些操作，并且持续更新结算结果。
  - 可以使用Scala、Java、Python或R中的DataSet／DataFrame API来表示流聚合、事件时间
    窗口、流到批连接等。此外，
  - Structured Streaming会通过checkpoint和预写日志等机制来实现Exactly-Once语义

简单来说，对于开发人员来说，**根本不用去考虑是流式计算，还是批处理，只要使用同样的方式来编写计算操作即可**，Structured Streaming**提供了快速、可扩展、容错、端到端的一次性流处理**，而用户无需考虑更多细节



默认情况下，**结构化流式查询使用微批处理引擎进行处理，该引擎将数据流作为一系列小批处理作业进行处理，从而实现端到端的延迟，最短可达100毫秒，并且完全可以保证一次容错。**自Spark 2.3以来，引入了一种新的低延迟处理模式，称为连续处理**，它可以在至少一次保证的情况下实现低至1毫秒的端到端延迟**。也就是类似于 Flink 那样的实时流，而不是小批量处理。实际开发可以根据应用程序要求选择处理模式。



计算结果可以选择输出到多种设备并进行如下设定

1.output mode：以哪种方式将result table的数据写入sink

2.format/output sink的一些细节：数据格式、位置等。

3.query name：指定查询的标识。类似tempview的名字

4.trigger interval：触发间隔，如果不指定，默认会尽可能快速地处理数据

5.checkpoint地址：一般是hdfs上的目录。注意：Socket不支持数据恢复，如果设置了，第二次启动会报错 ,Kafka支持



![image-20210818204659702](.\图片\kakfa偏移量管理.png)

