# Hive

周一：	select  date_add(next_day("2019-08-08","mo"),-7)  



## hive内存分配问题

**给map、reduce task分配合理的内存**

**map、reduce task处理合理的数据**

默认map task分配了多少内存，使用的缺省参数每个task分配200M内存【mapred.child.java.opts】

mapred.max.split.size=128000000

hive.exec.reducers.bytes.per.reducer=128000000

mapreduce.map.memory.mb=8192

mapreduce.reduce.memory.mb=5120

io.sort.mb=50



## 动态分区

set hive.exec.dynamic.partition.mode=nonstrict;

set hive.exec.dynamic.partition=true --默认是true

set hive.exec.max.dynamic.partitions = 1000

set hive.exec.max.dynamic.partitions.pernode = 100   每个mr创建多少个分区

set hive.exec.max.created.files =1000     每个mr创建的最大文件数量



# Tez

![image-20210516112331136](.\图片\Tez.png)



# 数仓理论

缓慢变化维：

```text
	缓慢变化维（SCD；Slowly Changing Dimensions）。在现实世界中，维度的属性随着时间的流失发生缓慢的变化（缓慢是相对事实表而言，事实表数据变化的速度比维度表快）。
	处理维度表的历史变化信息的问题称为处理缓慢变化维的问题，简称SCD问题。处理缓慢变化维的方法有以下几种常见方式：
        保留原值
        直接覆盖
        增加新属性列
        快照表
        拉链表
```


周期性事实表：



## 快照表

每天保留一份全量数据。
简单、高效。缺点是信息重复，浪费磁盘空间。
适用范围：维表不能太大
使用场景多，范围广；一般而言维表都不大。

## 拉链表

拉链表适合于：表的数据量大，而且数据会发生新增和变化，但是大部分是不变的（数据发生变化的百分比不大），且是缓慢变化的（如电商中用户信息表中的某些用户基本属性不可能每天都变化）。主要目的是节省存储空间。

适用场景：

1. 表的数据量大
2. 表中部分字段会被更新
3. 表中记录变量的比例不高
4. 需要保留历史信息

**拉链表一般不进行分区**

1、初始化

​	数据初始化，直接插入，，start_date采用插入日期，end_date采用默认值"9999-12-31"

2、插入数据

​	插入数据分为两部分

​		1) 当日数据直接插入即可

​		2) 和之前的数据做链接，然后插入，并修改为当前日期

3、回滚

​		从end_date去考虑。

​		分区<end_date，数据保留

​		分区>=end_date，修改为"9999-12-31"

4、使用

​	

**方案二**

​	**保存一段时间的增量数据，定期对拉链表做备份（如一个月做一次备份）；如需回滚，直接在备份的拉链表上重跑**



## 周期性事实表_拉链表实现





# Airflow

义也使用Python编写。

功能强大。支持多种不同类型的作业，可以自定义不同的作业，shell、python、MySQL、Oracle、Hive等等。

简洁明了。



体系结构

​	![image-20210523191456309](.\图片\Airflow.png)

安装参考拉钩文档。

![image-20210523201746113](.\图片\crontab.png)

* 代表所有的取值范围内的数字。如月份字段为*，则表示1到12个月；
* */ 代表每一定时间间隔的意思。如分钟字段为*/10，表示每10分钟执行1次；
- 代表从某个区间范围，是闭区间。如2-5表示2,3,4,5，小时字段中0-23/2表示在0~23点范围内每2个小时执行一次；
- , 分散的数字（不连续）。如1,2,3,4,7,9；

# Atlas

linkedin的开源项目，whereHows



表结构信息

数据的存储空间，读写记录，

数据的血缘关系

数据的业务属性信息



架构

![image-20210523211035883](.\图片\Atlas元数据.png)



使用方法：





# Griffin

**为什么要做数据质量监控**

1、数据不一致

​		数据来源比较多，且早期没有进行统一规划设计。

2、数据不完整

​		关键信息填写的不够完整。

3、数据不合规

​		五花八门的系统，没有统一的管理平台和数据源头，数据全生命周期管理不完整。

4、数据不可控

​		数据多头管理，缺少统一的标准。

5、数据冗余

​		

数据质量监控方法：

​	1、设计思路

​		数据、规则、告警、反馈

​	2、技术方案

​		



架构

![image-20210523220159632](.\图片\griffiin.png)

define：负责定义数据质量统计的维度，比如数据质量的时间跨度、统计的目标

measure：主要负责执行统计任务，生成统计结果

analyze：主要负责保存和展示
